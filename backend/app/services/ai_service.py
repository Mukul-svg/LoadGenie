"""
AI service for generating k6 scripts using Google Gemini
"""

import json
import asyncio
import time
import warnings
import re
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List

from google import genai
from google.genai import types

from app.core.config import settings
from app.core.logging import get_logger

# Suppress Pydantic warning from google-genai library
warnings.filterwarnings(
    "ignore", 
    message=".*<built-in function any> is not a Python type.*", 
    category=UserWarning
)

logger = get_logger(__name__)

class AIServiceError(Exception):
    """Custom exception for AI service errors"""
    pass

class AIService:
    """AI service for generating k6 load testing scripts"""
    
    def __init__(self):
        """Initialize the AI service"""
        # Validate configuration
        settings.validate()
        
        self.api_key = settings.GEMINI_API_KEY
        self.model = settings.AI_MODEL
        self.temperature = settings.AI_TEMPERATURE
        self.max_retries = settings.AI_MAX_RETRIES
        self.timeout = settings.AI_TIMEOUT
        
        # Initialize client and executor
        self.client = genai.Client(api_key=self.api_key)
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        logger.info(f"AI Service initialized with model: {self.model}")
    
    def _generate_sync(self, description: str) -> Dict[str, str]:
        """Synchronous generation method to be called in thread executor"""
        retry_count = 0
        last_exception = None
        
        while retry_count < self.max_retries:
            try:
                logger.info(f"Generation attempt {retry_count + 1}/{self.max_retries}")
                
                contents = [
                    types.Content(
                        role="user",
                        parts=[
                            types.Part.from_text(text=description),
                        ],
                    ),
                ]
                
                generate_content_config = types.GenerateContentConfig(
                    temperature=self.temperature,
                    response_mime_type="application/json",
                    response_schema=genai.types.Schema(
                        type=genai.types.Type.OBJECT,
                        required=["k6_script"],
                        properties={
                            "k6_script": genai.types.Schema(
                                type=genai.types.Type.STRING,
                            ),
                        },
                    ),
                    system_instruction=[
                        types.Part.from_text(
                            text=r"""You are an expert performance engineer specializing in creating robust, production-ready k6 JavaScript scripts that gracefully handle ANY type of API and real-world failure scenarios.

üéØ CORE PHILOSOPHY: Generate scripts that are ADAPTIVE and RESILIENT to unknown API behaviors, not rigid test scripts that break on unexpected responses.

üîß UNIVERSAL REQUIREMENTS (Apply to ALL APIs):
1. ADAPTIVE ERROR HANDLING - Scripts must handle unexpected responses gracefully
2. INTELLIGENT RETRY LOGIC - Distinguish between retryable (5xx) and business logic (4xx) errors  
3. FLEXIBLE RESPONSE VALIDATION - Work with varying response formats and structures
4. COMPREHENSIVE LOGGING - Detailed context for debugging any API behavior
5. REALISTIC THRESHOLDS - Account for business logic failures and API variations
6. GRACEFUL DEGRADATION - Continue testing even when some endpoints fail
7. UNIVERSAL AUTH HANDLING - Support multiple authentication patterns
8. DEFENSIVE PROGRAMMING - Assume nothing about API behavior

üåê UNIVERSAL ERROR HANDLING STRATEGY:
- 2xx: Success responses (continue normally)
- 4xx: Business logic/validation errors (log and continue, often acceptable)
- 5xx: Server errors (retry with exponential backoff)
- Network errors: Retry with backoff
- Parsing errors: Log and continue with degraded functionality

üìã ADAPTIVE SCRIPT STRUCTURE:
```javascript
import http from 'k6/http';
import { sleep, check } from 'k6';

// Universal configuration
export const options = {
  stages: [
    { duration: '30s', target: 3 },
    { duration: '1m', target: 5 },
    { duration: '30s', target: 0 },
  ],
  thresholds: {
    // Lenient thresholds for real-world APIs
    'http_req_failed': ['rate<0.2'],     // 20% failure tolerance
    'checks': ['rate>0.8'],              // 80% success rate
    'http_req_duration': ['p(95)<5000'], // 5s response time tolerance
  },
};

// Universal retry function with intelligent error classification
function smartRetry(requestFunc, maxRetries = 3, context = 'request') {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = requestFunc();
      
      // Log response for debugging
      console.log(`\${context} attempt \${attempt}: \${response.status}`);
      
      // Success or client error (don't retry 4xx)
      if (response.status < 500) {
        return response;
      }
      
      // Server error - retry with backoff
      if (attempt < maxRetries) {
        const delay = Math.min(Math.pow(2, attempt) * 1000, 10000); // Cap at 10s
        console.log(`Server error \${response.status}, retrying in \${delay}ms...`);
        sleep(delay / 1000);
      }
      
    } catch (error) {
      console.log(`\${context} network error on attempt \${attempt}: \${error}`);
      if (attempt < maxRetries) {
        sleep(Math.pow(2, attempt));
      }
    }
  }
  
  console.log(`\${context} failed after \${maxRetries} attempts`);
  return null;
}

// Universal response validator
function validateResponse(response, context = 'response') {
  if (!response) {
    console.log(`‚ùå \${context}: No response received`);
    return { isValid: false, data: null, error: 'No response' };
  }
  
  // Status code analysis
  const isSuccess = response.status >= 200 && response.status < 300;
  const isClientError = response.status >= 400 && response.status < 500;
  const isServerError = response.status >= 500;
  
  console.log(`üìä \${context}: Status \${response.status} (\${isSuccess ? 'success' : isClientError ? 'client-error' : isServerError ? 'server-error' : 'unknown'})`);
  
  // Try to parse JSON (but don't fail if it's not JSON)
  let data = null;
  let isJson = false;
  
  if (response.body && response.body.length > 0) {
    try {
      data = JSON.parse(response.body);
      isJson = true;
      console.log(`‚úÖ \${context}: Valid JSON response`);
    } catch (e) {
      console.log(`‚ö†Ô∏è \${context}: Non-JSON response: \${response.body.substring(0, 100)}...`);
    }
  }
  
  return {
    isValid: response.status < 500, // Consider 4xx as "valid" business logic
    isSuccess,
    isClientError,
    isServerError,
    isJson,
    data,
    status: response.status,
    error: isServerError ? 'Server error' : isClientError ? 'Client error' : null
  };
}

// Universal check pattern
function universalCheck(response, checkName, expectations = {}) {
  const validation = validateResponse(response, checkName);
  
  return check(response, {
    [`\${checkName}: Response received`]: (r) => r !== null,
    [`\${checkName}: Status acceptable`]: (r) => validation.isValid,
    [`\${checkName}: Response processable`]: (r) => {
      if (validation.isSuccess) return true;
      if (validation.isClientError) {
        console.log(`üîç \${checkName}: Business logic response - \${r.body}`);
        return expectations.allowClientErrors !== false; // Default allow
      }
      return false;
    }
  });
}
```

üîÑ UNIVERSAL WORKFLOW PATTERN:
1. **Endpoint Discovery**: Try endpoints, adapt to what's available
2. **Authentication Flexibility**: Support multiple auth patterns (Bearer, Basic, API Key, etc.)
3. **Data Structure Adaptation**: Work with whatever response format the API provides
4. **Business Logic Tolerance**: Accept that APIs have business rules that cause "errors"
5. **Performance Awareness**: Measure and adapt to API performance characteristics

üéØ ADAPTIVE TESTING EXAMPLES:

**Flexible Authentication:**
```javascript
function attemptAuthentication(credentials, baseUrl) {
  const authMethods = [
    () => http.post(`\${baseUrl}/auth/login`, JSON.stringify(credentials), {headers: {'Content-Type': 'application/json'}}),
    () => http.post(`\${baseUrl}/api/auth/login`, JSON.stringify(credentials), {headers: {'Content-Type': 'application/json'}}),
    () => http.post(`\${baseUrl}/login`, JSON.stringify(credentials), {headers: {'Content-Type': 'application/json'}}),
  ];
  
  for (const method of authMethods) {
    const response = smartRetry(method, 2, 'auth');
    if (response && response.status < 400) {
      return extractToken(response);
    }
  }
  return null;
}

function extractToken(response) {
  try {
    const data = JSON.parse(response.body);
    return data.token || data.accessToken || data.access_token || data.authToken || data.jwt;
  } catch (e) {
    // Try to extract from headers
    return response.headers.Authorization || response.headers.authorization;
  }
}
```

**Adaptive Resource Testing:**
```javascript
function testResourceEndpoints(baseUrl, authHeaders) {
  const commonEndpoints = [
    'users', 'products', 'items', 'data', 'resources',
    'orders', 'posts', 'articles', 'documents'
  ];
  
  for (const endpoint of commonEndpoints) {
    const response = smartRetry(() => 
      http.get(`\${baseUrl}/api/\${endpoint}`, {headers: authHeaders}), 
      2, 
      endpoint
    );
    
    const validation = validateResponse(response, endpoint);
    
    if (validation.isSuccess && validation.data) {
      console.log(`‚úÖ Found working endpoint: \${endpoint}`);
      return { endpoint, data: validation.data };
    }
  }
  
  return null;
}
```

**Business Logic Error Handling:**
```javascript
function handleBusinessLogicOperation(response, operationName) {
  const validation = validateResponse(response, operationName);
  
  return check(response, {
    [`\${operationName}: Operation completed`]: (r) => {
      if (validation.isSuccess) {
        console.log(`‚úÖ \${operationName}: Success`);
        return true;
      }
      
      if (validation.isClientError) {
        console.log(`‚ö†Ô∏è \${operationName}: Business rule prevented operation - \${r.body}`);
        return true; // Business logic errors are acceptable
      }
      
      console.log(`‚ùå \${operationName}: Technical failure - \${r.status}`);
      return false;
    }
  });
}
```

üéØ KEY PRINCIPLES:
- **Assume Nothing**: APIs vary wildly in behavior, structure, and error handling
- **Log Everything**: Comprehensive logging helps debug unknown API behaviors  
- **Fail Gracefully**: One failed endpoint shouldn't break the entire test
- **Adapt and Continue**: Scripts should learn and adapt to API responses
- **Business Logic Awareness**: Distinguish between technical failures and business rules
- **CRITICAL**: Generate syntactically correct JavaScript - validate brace matching, string termination, and variable declarations

ALWAYS use the exact JSON format: {"k6_script": "your_complete_script_here"}
Generate scripts that work with ANY API by being adaptive, defensive, and resilient to unexpected behaviors.
ENSURE the generated JavaScript has proper syntax with matching braces and valid structure.
                            """
                        ),
                    ],
                )

                # Collect the full response with timeout
                full_response = ""
                start_time = time.time()
                
                for chunk in self.client.models.generate_content_stream(
                    model=self.model,
                    contents=contents,
                    config=generate_content_config,
                ):
                    if time.time() - start_time > self.timeout:
                        raise AIServiceError(f"Generation timeout after {self.timeout} seconds")
                        
                    if chunk.text:
                        full_response += chunk.text
                
                # Parse and validate the JSON response
                if not full_response.strip():
                    raise AIServiceError("Empty response from AI service")
                    
                try:
                    result = json.loads(full_response)
                    
                    # Additional validation
                    if not result.get("k6_script"):
                        raise AIServiceError("Generated script is empty or missing")
                    
                    # Enhanced validation of k6 script content
                    script = result["k6_script"]
                    
                    # Run comprehensive validation
                    validation_report = self._validate_script_quality(script)
                    
                    if not validation_report["is_valid"]:
                        error_msg = f"Generated script validation failed: {validation_report['errors']}"
                        logger.error(error_msg)
                        raise AIServiceError(error_msg)
                    
                    # Enhance script if needed
                    if validation_report["quality_score"] < 70:
                        logger.info(f"Enhancing script quality (current score: {validation_report['quality_score']})")
                        script = self._enhance_script_if_needed(script, validation_report)
                        result["k6_script"] = script
                    
                    # Log quality assessment
                    logger.info(f"‚úÖ Script quality: {validation_report['quality_rating']} "
                              f"(score: {validation_report['quality_score']}/100)")
                    
                    if validation_report["warnings"]:
                        logger.warning(f"Script warnings: {validation_report['warnings']}")
                    
                    if validation_report["suggestions"]:
                        logger.info(f"Optimization suggestions: {validation_report['suggestions']}")
                    
                    logger.info("‚úÖ Successfully generated and validated production-ready k6 script")
                    logger.info(f"Script length: {len(script)} characters")
                    return result
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Failed to parse AI response as JSON: {e}")
                    logger.error(f"Raw response: {full_response[:500]}...")
                    raise AIServiceError(f"Invalid JSON response from AI service: {e}")
                    
            except Exception as e:
                last_exception = e
                retry_count += 1
                
                if retry_count < self.max_retries:
                    wait_time = 2 ** retry_count  # Exponential backoff
                    logger.warning(f"Generation failed (attempt {retry_count}), retrying in {wait_time}s: {e}")
                    time.sleep(wait_time)
                else:
                    logger.error(f"All generation attempts failed: {e}")
        
        # If we get here, all retries failed
        if isinstance(last_exception, AIServiceError):
            raise last_exception
        raise AIServiceError(f"Failed to generate content after {self.max_retries} attempts: {str(last_exception)}")
    
    async def generate_k6_script(self, description: str) -> Dict[str, str]:
        """
        Generate a k6 script based on the scenario description
        
        Args:
            description: The scenario description for load testing
            
        Returns:
            Dict containing the generated k6 script
            
        Raises:
            AIServiceError: If generation fails
        """
        if not description or not description.strip():
            raise AIServiceError("Description cannot be empty")
            
        if len(description.strip()) < 10:
            raise AIServiceError("Description too short, please provide more details")
            
        logger.info(f"Generating k6 script for description: {description[:100]}...")
        start_time = time.time()
        
        try:
            # Run the synchronous generation in a thread executor
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self.executor, 
                self._generate_sync, 
                description
            )
            
            generation_time = time.time() - start_time
            logger.info(f"Script generation completed in {generation_time:.2f} seconds")
            
            return result
            
        except AIServiceError:
            raise
        except Exception as e:
            logger.error(f"Unexpected error in generate_k6_script: {e}")
            raise AIServiceError(f"Unexpected error: {str(e)}")

    async def analyze_test_results(self, analysis_prompt: str) -> Dict[str, str]:
        """
        Analyze test results for anomalies using AI
        
        Args:
            analysis_prompt: The analysis prompt containing test data
            
        Returns:
            Dict containing the analysis results in the expected format
            
        Raises:
            AIServiceError: If analysis fails
        """
        if not analysis_prompt or not analysis_prompt.strip():
            raise AIServiceError("Analysis prompt cannot be empty")
            
        logger.info("Analyzing test results with AI...")
        start_time = time.time()
        
        try:
            # Run the synchronous analysis in a thread executor
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(
                self.executor, 
                self._analyze_sync, 
                analysis_prompt
            )
            
            analysis_time = time.time() - start_time
            logger.info(f"Test analysis completed in {analysis_time:.2f} seconds")
            
            return result
            
        except AIServiceError:
            raise
        except Exception as e:
            logger.error(f"Unexpected error in analyze_test_results: {e}")
            raise AIServiceError(f"Unexpected error: {str(e)}")

    def _analyze_sync(self, analysis_prompt: str) -> Dict[str, str]:
        """Synchronous analysis method for test results"""
        retry_count = 0
        last_exception = None
        
        while retry_count < self.max_retries:
            try:
                logger.info(f"Analysis attempt {retry_count + 1}/{self.max_retries}")
                
                contents = [
                    types.Content(
                        role="user",
                        parts=[
                            types.Part.from_text(text=analysis_prompt),
                        ],
                    ),
                ]
                
                generate_content_config = types.GenerateContentConfig(
                    temperature=0.3,  # Lower temperature for more consistent analysis
                    response_mime_type="application/json",
                    response_schema=genai.types.Schema(
                        type=genai.types.Type.OBJECT,
                        required=["analysis_result"],
                        properties={
                            "analysis_result": genai.types.Schema(
                                type=genai.types.Type.STRING,
                            ),
                        },
                    ),
                    system_instruction=[
                        types.Part.from_text(
                            text="""You are an expert performance engineer analyzing load test results for anomalies and performance issues.

Your task is to analyze the provided test data and return a JSON analysis in the exact format requested.

CRITICAL: Return your analysis as a JSON string in the "analysis_result" field, formatted exactly like this:
{
  "analysis_result": "{\"anomalies_detected\": boolean, \"severity\": \"low|medium|high|critical\", \"issues\": [\"list of issues\"], \"recommendations\": [\"list of recommendations\"], \"confidence\": 0.0-1.0}"
}

Guidelines for analysis:
- High error rates (>5%) are concerning
- Slow response times (>2s avg) are concerning  
- Low throughput relative to virtual users indicates problems
- Compare with historical patterns when available
- Provide specific, actionable recommendations
- Set confidence based on data quality and clarity of patterns

Always ensure the analysis_result contains valid JSON that can be parsed."""
                        ),
                    ],
                )

                # Collect the full response with timeout
                full_response = ""
                start_time = time.time()
                
                for chunk in self.client.models.generate_content_stream(
                    model=self.model,
                    contents=contents,
                    config=generate_content_config,
                ):
                    if time.time() - start_time > self.timeout:
                        raise AIServiceError(f"Analysis timeout after {self.timeout} seconds")
                        
                    if chunk.text:
                        full_response += chunk.text
                
                # Parse and validate the JSON response
                if not full_response.strip():
                    raise AIServiceError("Empty response from AI service")
                    
                try:
                    result = json.loads(full_response)
                    
                    # Validate the analysis result
                    if not result.get("analysis_result"):
                        raise AIServiceError("Analysis result is missing")
                    
                    # Try to parse the nested JSON to validate it
                    try:
                        analysis_data = json.loads(result["analysis_result"])
                        required_fields = ["anomalies_detected", "severity", "issues", "recommendations", "confidence"]
                        if not all(field in analysis_data for field in required_fields):
                            raise AIServiceError(f"Analysis result missing required fields: {required_fields}")
                    except json.JSONDecodeError:
                        raise AIServiceError("Analysis result is not valid JSON")
                    
                    logger.info("‚úÖ Successfully generated test analysis")
                    return result
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Failed to parse AI response as JSON: {e}")
                    logger.error(f"Raw response: {full_response[:500]}...")
                    raise AIServiceError(f"Invalid JSON response from AI service: {e}")
                    
            except Exception as e:
                last_exception = e
                retry_count += 1
                
                if retry_count < self.max_retries:
                    wait_time = 2 ** retry_count  # Exponential backoff
                    logger.warning(f"Analysis failed (attempt {retry_count}), retrying in {wait_time}s: {e}")
                    time.sleep(wait_time)
                else:
                    logger.error(f"All analysis attempts failed: {e}")
        
        # If we get here, all retries failed
        if isinstance(last_exception, AIServiceError):
            raise last_exception
        raise AIServiceError(f"Failed to analyze results after {self.max_retries} attempts: {str(last_exception)}")

    def _check_javascript_syntax(self, script: str) -> List[str]:
        """
        Minimal JavaScript syntax check for K6 scripts.
        Temporarily disabled to avoid blocking valid scripts.
        
        Args:
            script: JavaScript code to validate
            
        Returns:
            List of syntax error messages (empty for now)
        """
        errors = []
        
        # TEMPORARILY DISABLED - syntax validation was too strict
        # and blocking valid K6 scripts with false positives
        
        # Only check for absolutely critical missing elements
        if len(script.strip()) < 20:
            errors.append("Script appears to be empty or too short")
            return errors
        
        # Only flag if script is completely broken (missing core K6 elements)
        if len(script) > 100:
            if not re.search(r'import.*http', script, re.IGNORECASE):
                logger.warning("Script missing HTTP import - may not work properly")
                # Don't block - AI might have good reason for this
            
            if not re.search(r'export.*function', script, re.IGNORECASE):
                logger.warning("Script missing export function - may not work properly") 
                # Don't block - AI might have good reason for this
        
        # Only check for extremely obvious problems
        if script.count('"') % 2 != 0 and script.count("'") % 2 != 0:
            # Both quote types are unbalanced - likely real problem
            pass  # But still don't block - K6 might handle it
        
        # Log info but don't block
        open_braces = script.count('{')
        close_braces = script.count('}')
        if abs(open_braces - close_braces) > 5:
            logger.warning(f"Brace imbalance detected: {open_braces} open, {close_braces} close")
            # Don't block - auto-fix will handle this
        
        return errors  # Return empty list - let AI generate freely

    def _validate_script_quality(self, script: str) -> Dict[str, any]:
        """Validate the quality and completeness of generated K6 script"""
        validation_report = {
            "is_valid": True,
            "quality_score": 0,
            "errors": [],
            "warnings": [],
            "suggestions": []
        }
        
        # CRITICAL: Syntax validation first
        syntax_errors = self._check_javascript_syntax(script)
        if syntax_errors:
            validation_report["errors"].extend(syntax_errors)
            validation_report["is_valid"] = False
            return validation_report  # Return early if syntax is broken
        
        # Critical validations (must pass)
        critical_checks = [
            ("import.*http", "HTTP module import"),
            ("import.*sleep", "Sleep function import"),
            ("import.*check", "Check function import"),
            ("export default function", "Default function export"),
            ("export.*options", "K6 options configuration"),
            ("sleep\\(", "Think time implementation"),
            ("check\\(", "Response validation"),
        ]
        
        for pattern, description in critical_checks:
            if not re.search(pattern, script):
                validation_report["errors"].append(f"Missing: {description}")
                validation_report["is_valid"] = False
            else:
                validation_report["quality_score"] += 10
        
        # Quality enhancements (recommended)
        quality_checks = [
            ("try.*catch", "Error handling", 15),
            ("console\\.(log|error)", "Debugging logs", 10),
            ("retryRequest|retry|smartRetry", "Retry mechanisms", 15),
            ("rate<0\\.[0-9]", "Realistic failure thresholds", 10),
            ("p\\(95\\)<[0-9]+", "Performance thresholds", 10),
            ("JSON\\.parse", "JSON parsing", 5),
            ("headers.*Authorization", "Authentication handling", 10),
            ("response\\.status", "Status code validation", 5),
            ("scenarios|stages", "Load test configuration", 10),
            # Universal error handling patterns
            ("status.*<.*500", "5xx error classification", 15),
            ("status.*>=.*400.*<.*500", "4xx business logic handling", 15),
            ("business.*logic|client.*error", "Business logic awareness", 15),
            ("adaptive|flexible|universal", "Adaptive API handling", 10),
            ("validateResponse|validation", "Response validation", 10),
            ("exponential.*backoff|Math\\.pow", "Exponential backoff", 10),
            ("graceful.*degradation|continue.*testing", "Graceful degradation", 10),
            ("extractToken|auth.*method", "Flexible authentication", 10),
            ("endpoint.*discovery|commonEndpoints", "Endpoint discovery", 10),
            ("network.*error|connection.*error", "Network error handling", 10),
            ("defensive.*programming", "Defensive programming", 5),
        ]
        
        for pattern, description, points in quality_checks:
            if re.search(pattern, script):
                validation_report["quality_score"] += points
            else:
                validation_report["warnings"].append(f"Consider adding: {description}")
        
        # Security and best practices
        security_checks = [
            ("hardcoded.*password", "Hardcoded credentials detected"),
            ("http://.*production", "HTTP in production URLs"),
            ("console\\.log.*password", "Password logging detected"),
        ]
        
        for pattern, warning in security_checks:
            if re.search(pattern, script, re.IGNORECASE):
                validation_report["warnings"].append(f"Security issue: {warning}")
        
        # Performance optimizations
        perf_suggestions = []
        if "sleep(0)" in script:
            perf_suggestions.append("Avoid sleep(0), use realistic think times")
        if "while(true)" in script:
            perf_suggestions.append("Avoid infinite loops in load tests")
        if script.count("http.get") + script.count("http.post") > 20:
            perf_suggestions.append("Consider modularizing large test scripts")
        
        validation_report["suggestions"] = perf_suggestions
        
        # Calculate final quality rating
        max_score = 100
        quality_percentage = min(validation_report["quality_score"], max_score)
        validation_report["quality_rating"] = "Excellent" if quality_percentage >= 80 else \
                                           "Good" if quality_percentage >= 60 else \
                                           "Fair" if quality_percentage >= 40 else "Poor"
        
        return validation_report

    def _fix_syntax_errors(self, script: str) -> str:
        """
        Attempt to fix common syntax errors in JavaScript
        
        Args:
            script: JavaScript code with potential syntax errors
            
        Returns:
            Fixed JavaScript code
        """
        fixed_script = script
        
        # Fix extra closing braces at the end
        fixed_script = fixed_script.strip()
        while (fixed_script.endswith('}}') and 
               fixed_script.count('{') < fixed_script.count('}')):
            fixed_script = fixed_script[:-1].strip()
        
        # Fix common brace imbalances
        open_braces = fixed_script.count('{')
        close_braces = fixed_script.count('}')
        
        if open_braces > close_braces:
            # Add missing closing braces
            missing_braces = open_braces - close_braces
            fixed_script += '\n' + '}' * missing_braces
        elif close_braces > open_braces:
            # Remove extra closing braces from the end
            extra_braces = close_braces - open_braces
            for _ in range(extra_braces):
                last_brace_idx = fixed_script.rfind('}')
                if last_brace_idx != -1:
                    fixed_script = fixed_script[:last_brace_idx] + fixed_script[last_brace_idx+1:]
        
        # Fix unterminated strings (basic fix)
        lines = fixed_script.split('\n')
        for i, line in enumerate(lines):
            # Count quotes, excluding commented lines
            if '//' not in line:
                if line.count('"') % 2 != 0:
                    lines[i] = line + '"'  # Add missing quote
                if line.count("'") % 2 != 0:
                    lines[i] = line + "'"  # Add missing quote
        
        fixed_script = '\n'.join(lines)
        
        logger.info("Applied automatic syntax fixes to the script")
        return fixed_script

    def _enhance_script_if_needed(self, script: str, validation_report: Dict) -> str:
        """Enhance script based on validation report"""
        
        # CRITICAL: Fix syntax errors first if they exist
        if not validation_report["is_valid"] and validation_report["errors"]:
            logger.info("Attempting to fix syntax errors automatically...")
            script = self._fix_syntax_errors(script)
            
            # Re-validate after fixes
            new_validation = self._check_javascript_syntax(script)
            if new_validation:
                logger.warning(f"Some syntax issues remain after auto-fix: {new_validation[:2]}")
                # But continue anyway - K6 might still be able to run it
            else:
                logger.info("‚úÖ Syntax errors successfully fixed")
        
        if validation_report["quality_score"] >= 70:
            return script  # Script is already good
        
        # Add adaptive retry logic if missing
        if "retry" not in script.lower() and "smartRetry" not in script:
            retry_function = r"""
// Auto-generated universal retry function for any API
function smartRetry(requestFunc, maxRetries = 3, context = 'request') {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      const response = requestFunc();
      console.log(`${context} attempt ${attempt}: ${response.status}`);
      
      // Success or client error (don't retry 4xx)
      if (response.status < 500) return response;
      
      // Server error - retry with backoff
      if (attempt < maxRetries) {
        const delay = Math.min(Math.pow(2, attempt) * 1000, 10000);
        console.log(`Server error ${response.status}, retrying in ${delay}ms...`);
        sleep(delay / 1000);
      }
    } catch (error) {
      console.log(`${context} network error: ${error}`);
      if (attempt < maxRetries) sleep(Math.pow(2, attempt));
    }
  }
  return null;
}

// Universal response validator for any API
function validateResponse(response, context = 'response') {
  if (!response) return { isValid: false, data: null, error: 'No response' };
  
  const isSuccess = response.status >= 200 && response.status < 300;
  const isClientError = response.status >= 400 && response.status < 500;
  
  let data = null;
  try {
    data = JSON.parse(response.body);
  } catch (e) {
    console.log(`Non-JSON response: ${response.body.substring(0, 100)}...`);
  }
  
  return {
    isValid: response.status < 500,
    isSuccess,
    isClientError,
    data,
    status: response.status
  };
}
"""
            script = retry_function + "\n" + script
        
        return script

    async def validate_and_improve_script(self, script: str) -> Dict[str, any]:
        """
        Validate a K6 script and provide improvement suggestions
        
        Args:
            script: The K6 script to validate
            
        Returns:
            Dict containing validation results and improvement suggestions
        """
        if not script or not script.strip():
            return {
                "is_valid": False,
                "errors": ["Script is empty"],
                "quality_score": 0,
                "quality_rating": "Invalid",
                "suggestions": ["Provide a valid K6 script"]
            }
        
        validation_report = self._validate_script_quality(script)
        
        # Add overall assessment
        validation_report["overall_assessment"] = {
            "production_ready": validation_report["is_valid"] and validation_report["quality_score"] >= 70,
            "needs_improvement": validation_report["quality_score"] < 70,
            "has_critical_issues": not validation_report["is_valid"]
        }
        
        # Add specific recommendations based on score
        if validation_report["quality_score"] < 50:
            validation_report["recommendations"] = [
                "Add comprehensive error handling with try-catch blocks",
                "Implement adaptive retry mechanisms for any API type", 
                "Include detailed logging for debugging unknown API behaviors",
                "Use realistic performance thresholds that account for business logic",
                "Add flexible response validation that works with any response format",
                "Implement graceful degradation when endpoints fail",
                "Use universal authentication patterns that work with multiple auth types"
            ]
        elif validation_report["quality_score"] < 70:
            validation_report["recommendations"] = [
                "Enhance error handling to be more adaptive",
                "Add comprehensive logging for better API debugging",
                "Consider implementing universal retry logic for any API type",
                "Make response validation more flexible for different APIs"
            ]
        else:
            validation_report["recommendations"] = ["Script meets universal production standards for any API type"]
        
        logger.info(f"Script validation completed: {validation_report['quality_rating']} "
                   f"(score: {validation_report['quality_score']}/100)")
        
        return validation_report

# Global AI service instance
_ai_service = None

def get_ai_service() -> AIService:
    """Get or create the AI service instance"""
    global _ai_service
    if _ai_service is None:
        _ai_service = AIService()
    return _ai_service
